# üéôÔ∏è MeetVocal - Transcription Automatique de R√©unions

## üìã Description du Projet

MeetVocal est une application de transcription automatique qui transforme vos enregistrements audio de r√©unions en comptes-rendus professionnels structur√©s. Le syst√®me utilise l'intelligence artificielle pour :

- ‚úÖ Transcrire automatiquement les enregistrements audio
- üë• Identifier et s√©parer les diff√©rents intervenants (diarisation)
- üßπ Nettoyer le texte (suppression des h√©sitations, correction de la ponctuation)
- üìù G√©n√©rer des comptes-rendus structur√©s
- üíæ Exporter en PDF et DOCX

---

## üèóÔ∏è Architecture du Projet

```
transcription_meetvocal/
‚îÇ
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îî‚îÄ‚îÄ IA/
‚îÇ       ‚îú‚îÄ‚îÄ transcriptiondiarization.py  # Transcription + identification des locuteurs
‚îÇ       ‚îú‚îÄ‚îÄ extractions.py               # Extraction et organisation du texte
‚îÇ       ‚îú‚îÄ‚îÄ cleaning.py                  # Nettoyage du texte transcrit
‚îÇ       ‚îú‚îÄ‚îÄ resume.py                    # G√©n√©ration de r√©sum√©s (BART + Groq)
‚îÇ       ‚îú‚îÄ‚îÄ pipeline_service.py          # Orchestration compl√®te du pipeline
‚îÇ       ‚îî‚îÄ‚îÄ save_pdf.py                  # Export PDF et DOCX
‚îÇ
‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îî‚îÄ‚îÄ SQL_File.sql                     # Sch√©ma de la base de donn√©es PostgreSQL
‚îÇ
‚îú‚îÄ‚îÄ main.py                              # Point d'entr√©e de l'application
‚îú‚îÄ‚îÄ .env                                 # Variables d'environnement (√† cr√©er)
‚îî‚îÄ‚îÄ README.md                            # Ce fichier
```

---

## üöÄ Installation et Configuration

### 1Ô∏è‚É£ Pr√©requis

Avant de commencer, assurez-vous d'avoir install√© :

- **Python 3.8+** ([T√©l√©charger Python](https://www.python.org/downloads/))
- **FFmpeg** (pour la conversion audio)
- **PostgreSQL** (pour la base de donn√©es)

#### Installation de FFmpeg :

**Windows :**
```bash
# Avec Chocolatey
choco install ffmpeg

# Ou t√©l√©charger depuis : https://ffmpeg.org/download.html
```

**macOS :**
```bash
brew install ffmpeg
```

**Linux (Ubuntu/Debian) :**
```bash
sudo apt update
sudo apt install ffmpeg
```

### 2Ô∏è‚É£ Cloner le Projet

```bash
git clone https://github.com/votre-username/transcription_meetvocal.git
cd transcription_meetvocal
```

### 3Ô∏è‚É£ Installer les D√©pendances Python

Cr√©ez un environnement virtuel et installez les packages :

```bash
# Cr√©er un environnement virtuel
python -m venv venv

# Activer l'environnement virtuel
# Windows :
venv\Scripts\activate
# macOS/Linux :
source venv/bin/activate

# Installer les d√©pendances
pip install -r requirements.txt
```

**Liste des d√©pendances principales :**
```txt
groq>=0.4.0
pyannote.audio>=3.0.0
transformers>=4.30.0
torch>=2.0.0
python-dotenv>=1.0.0
fpdf>=1.7.2
python-docx>=0.8.11
```

### 4Ô∏è‚É£ Configuration des Cl√©s API

Cr√©ez un fichier `.env` √† la racine du projet :

```bash
touch .env
```

Ajoutez-y vos cl√©s API :

```env
# Cl√© API Groq (pour la transcription Whisper)
GROQ_API_KEY=votre_cle_groq_ici

# Token Hugging Face (pour la diarisation Pyannote)
HUGGINGFACE_TOKEN=votre_token_huggingface_ici
```

#### O√π obtenir les cl√©s ?

1. **Groq API** : [https://console.groq.com](https://console.groq.com)
   - Cr√©ez un compte gratuit
   - G√©n√©rez une cl√© API dans les param√®tres

2. **Hugging Face** : [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)
   - Cr√©ez un compte
   - G√©n√©rez un token d'acc√®s
   - Acceptez les conditions d'utilisation de `pyannote/speaker-diarization`

### 5Ô∏è‚É£ Configuration de la Base de Donn√©es (Optionnel)

Si vous souhaitez utiliser la persistance des donn√©es :

```bash
# Connectez-vous √† PostgreSQL
psql -U postgres

# Cr√©ez la base de donn√©es
CREATE DATABASE transcription_db;

# Ex√©cutez le script SQL
\c transcription_db
\i backend/SQL_File.sql
```

---

## üéØ Utilisation

### Utilisation Basique

```python
from backend.IA.pipeline_service import TranscriptionPipeline

# Initialiser le pipeline avec votre fichier audio
pipeline = TranscriptionPipeline(
    audio_file="chemin/vers/votre/audio.m4a",
    output_dir="./resultats"
)

# Lancer le traitement complet
results = pipeline.run(save_intermediary_files=True)

# Acc√©der aux r√©sultats
print(results["cleaned_text"])
print(results["summary"])
print(results["pdf_path"])
```

### Ex√©cution via le Script Principal

```bash
python main.py
```

---

## üìä Pipeline de Traitement

Le syst√®me suit un pipeline en 6 √©tapes :

```
1. üé§ Transcription + Diarisation
   ‚Üì (Groq Whisper + Pyannote)
   
2. üìÑ Extraction du Texte Pur
   ‚Üì (Suppression des m√©tadonn√©es)
   
3. üßπ Nettoyage du Texte
   ‚Üì (Suppression h√©sitations, correction ponctuation)
   
4. üìã G√©n√©ration du R√©sum√©
   ‚Üì (Groq LLM + BART)
   
5. üë• Organisation par Locuteur
   ‚Üì (S√©paration et r√©sum√©s individuels)
   
6. üíæ Export PDF/DOCX
   ‚Üì (G√©n√©ration des fichiers finaux)
```

---

## üìÅ Structure de la Base de Donn√©es

### Tables Principales

**utilisateurs** : Gestion des utilisateurs
```sql
- id_user (PRIMARY KEY)
- name
- email
- password
```

**fichiers_audio** : Enregistrements audio upload√©s
```sql
- id_audio (PRIMARY KEY)
- id_user (FOREIGN KEY)
- title
- file_path
- status
- num_speakers
- duration
- date_upload
```

**transcriptions** : Segments de transcription
```sql
- id_transcription (PRIMARY KEY)
- id_audio (FOREIGN KEY)
- text_brut
- start_time
- end_time
- speaker
- sequence_number
```

**resumes** : R√©sum√©s g√©n√©r√©s
```sql
- id_resume (PRIMARY KEY)
- id_audio (FOREIGN KEY)
- summary_text
- type_resume ('general' ou 'par_speaker')
- speaker
```

---

## üîß Modules D√©taill√©s

### `transcriptiondiarization.py`
- Convertit l'audio en WAV (16kHz, mono)
- Utilise **Groq Whisper** pour la transcription
- Utilise **Pyannote** pour identifier les locuteurs
- Fusionne timestamps + speakers + texte

### `cleaning.py`
- Supprime les mots de remplissage (euh, hum, etc.)
- Corrige la ponctuation
- G√®re les connecteurs logiques
- √âlimine les r√©p√©titions

### `resume.py`
- **M√©thode 1** : R√©sum√© local avec BART (Facebook)
- **M√©thode 2** : Compte-rendu structur√© avec Groq (LLaMA 3.3)
- Format professionnel avec sections :
  - R√©sum√© ex√©cutif
  - Contexte et objectif
  - Points cl√©s
  - D√©cisions prises
  - Actions √† entreprendre
  - Prochaines √©tapes

### `pipeline_service.py`
- Classe `TranscriptionPipeline` qui orchestre tout le processus
- G√®re les fichiers interm√©diaires
- Retourne un dictionnaire de r√©sultats complet

### `save_pdf.py`
- Export en PDF avec FPDF
- Export en DOCX avec python-docx

---

## üêõ R√©solution de Probl√®mes

### Erreur : "GROQ_API_KEY manquante"
‚û°Ô∏è V√©rifiez que votre fichier `.env` est bien √† la racine et contient les cl√©s

### Erreur : "ffmpeg not found"
‚û°Ô∏è Installez FFmpeg (voir section Installation)

### Erreur lors de la diarisation
‚û°Ô∏è V√©rifiez que vous avez accept√© les conditions sur le mod√®le Pyannote :
   [https://huggingface.co/pyannote/speaker-diarization](https://huggingface.co/pyannote/speaker-diarization)

### Performance lente
‚û°Ô∏è La diarisation et la transcription peuvent prendre du temps selon la longueur de l'audio
‚û°Ô∏è Utilisez un GPU si disponible (modification du code n√©cessaire)

---

## ü§ù Contribution

1. Forkez le projet
2. Cr√©ez une branche (`git checkout -b feature/amelioration`)
3. Committez vos changements (`git commit -m 'Ajout fonctionnalit√© X'`)
4. Pushez vers la branche (`git push origin feature/amelioration`)
5. Ouvrez une Pull Request

---

## üìù TODO / Am√©liorations Futures

- [ ] Interface web avec FastAPI ou Flask
- [ ] Support de plus de langues
- [ ] Int√©gration d'un syst√®me d'authentification complet
- [ ] Tableau de bord utilisateur
- [ ] Export en formats suppl√©mentaires (JSON, Markdown)
- [ ] Am√©lioration de la d√©tection des speakers (noms r√©els)
- [ ] Support GPU pour acc√©l√©rer le traitement

---

## üìÑ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de d√©tails.

---

## üë• Auteurs

D√©velopp√© par l'√©quipe MeetRecap

---

## üìû Support

Pour toute question ou probl√®me :
- Ouvrez une issue sur GitHub
- Consultez la documentation des APIs utilis√©es

---
