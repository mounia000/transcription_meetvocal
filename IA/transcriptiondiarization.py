# ============================================================
# üìÅ backend/IA/transcriptiondiarization.py
# ============================================================

import os
import subprocess
from dotenv import load_dotenv
from groq import Groq
from pyannote.audio import Pipeline

# ============================================================
# 1Ô∏è‚É£ Charger les variables d'environnement (.env)
# ============================================================
load_dotenv()
print("‚úÖ Cl√©s API charg√©es correctement.")

# ============================================================
# 2Ô∏è‚É£ V√©rifier la pr√©sence des cl√©s API
# ============================================================
groq_api_key = os.getenv("GROQ_API_KEY")
hf_token = os.getenv("HUGGINGFACE_TOKEN")

if not groq_api_key or not hf_token:
    raise ValueError("‚ùå Cl√©s API manquantes (Groq ou Hugging Face)")

# ============================================================
# 3Ô∏è‚É£ D√©finir les chemins de base (dossier courant, audio, etc.)
# ============================================================
base_dir = os.path.dirname(__file__)
audio_dir = os.path.join(base_dir, "audio")

# On cr√©e le dossier 'audio' s‚Äôil n‚Äôexiste pas encore
os.makedirs(audio_dir, exist_ok=True)

# Fichier audio par d√©faut (√† titre d‚Äôexemple, mais pas utilis√© automatiquement)
audio_path = os.path.join(audio_dir, "meet1.mp3")
wav_path = None  # ‚ö†Ô∏è on ne convertit plus automatiquement au chargement du module

# ============================================================
# 4Ô∏è‚É£ Fonction : conversion MP3 ‚Üí WAV (avec v√©rifications)
# ============================================================
def convert_to_wav(audio_path):
    """
    Convertit un fichier audio en WAV (16kHz mono).
    L√®ve une erreur si le fichier source n'existe pas.
    """
    if not os.path.exists(audio_path):
        raise FileNotFoundError(f"‚ùå Fichier audio introuvable : {audio_path}")

    base, ext = os.path.splitext(audio_path)
    wav_path = base + ".wav"

    if not os.path.exists(wav_path):
        print(f"üéß Conversion du fichier {audio_path} en {wav_path} ...")
        subprocess.run([
            "ffmpeg", "-y",
            "-i", audio_path,
            "-ar", "16000",
            "-ac", "1",
            wav_path
        ], check=True)
        print(f"‚úÖ Fichier WAV pr√™t : {wav_path}")
    else:
        print(f"‚ÑπÔ∏è Le fichier WAV existe d√©j√† : {wav_path}")

    return wav_path

# ============================================================
# 5Ô∏è‚É£ Initialisation du pipeline Pyannote
# ============================================================
print("‚è≥ Chargement du pipeline de diarisation (pyannote)...")
pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization", use_auth_token=hf_token)
print("‚úÖ Pipeline charg√© avec succ√®s !")

# ============================================================
# 6Ô∏è‚É£ Fonction utilitaire pour formater le temps (mm:ss.s)
# ============================================================
def format_time(seconds):
    minutes = int(seconds // 60)
    secs = seconds % 60
    return f"{minutes:02d}:{secs:04.1f}"

# ============================================================
# 7Ô∏è‚É£ Fusion diarisation + transcription
# ============================================================
def match_speaker_to_text(diar_segments, text_segments):
    """
    Associe les segments de texte aux locuteurs d√©tect√©s.
    """
    result = []
    for txt in text_segments:
        start = txt["start"]
        end = txt["end"]
        text = txt["text"].strip()

        # Trouver le locuteur le plus probable
        speaker = "UNKNOWN"
        for d in diar_segments:
            if d["start"] <= start <= d["end"]:
                speaker = d["speaker"]
                break

        start_f = format_time(start)
        end_f = format_time(end)
        result.append(f"[{start_f} - {end_f}] [{speaker}] {text}")
    return result

# ============================================================
# 8Ô∏è‚É£ Fonction principale : transcription avec diarisation
# ============================================================
def transcription_with_diarization(audio_file=None):
    """
    Retourne le texte complet avec diarisation et timestamps.
    Si audio_file est fourni, on l'utilise √† la place du fichier par d√©faut.
    """
    global audio_path, wav_path

    # üß© Utiliser le fichier re√ßu ou celui par d√©faut
    if audio_file:
        audio_path = audio_file
    if not os.path.exists(audio_path):
        raise FileNotFoundError(f"‚ùå Aucun fichier audio trouv√© √† : {audio_path}")

    # üéß Conversion en WAV
    wav_path = convert_to_wav(audio_path)

    # üë• Diarisation
    print("üéß D√©tection des intervenants...")
    diarization = pipeline(wav_path)
    segments = [
        {"start": t.start, "end": t.end, "speaker": s}
        for t, _, s in diarization.itertracks(yield_label=True)
    ]
    print(f"üë• Intervenants d√©tect√©s : {set(seg['speaker'] for seg in segments)}")

    # üéôÔ∏è Transcription via Groq
    print("\nüéôÔ∏è Lancement de la transcription compl√®te (Groq)...")
    client = Groq(api_key=groq_api_key)
    with open(wav_path, "rb") as file:
        transcription = client.audio.transcriptions.create(
            file=file,
            model="whisper-large-v3-turbo",
            response_format="verbose_json",
            timestamp_granularities=["segment"],
            language="fr"
        )

    # üß† Fusion des r√©sultats
    fusion = match_speaker_to_text(segments, transcription.segments)

    # üíæ Sauvegarde du texte final
    output_path = os.path.join(base_dir, "transcription_avec_diarisation.txt")
    with open(output_path, "w", encoding="utf-8") as f:
        f.write("\n".join(fusion))

    print(f"\n‚úÖ Transcription avec timestamps enregistr√©e ici : {output_path}\n")

    return "\n".join(fusion)
